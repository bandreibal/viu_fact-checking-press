{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import Cohere\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "COHERE_API_KEY = os.environ[\"COHERE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"data/sources_txt/\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_eval = ChatOpenAI(model_name='gpt-4-0125-preview', # gpt-4-0125-preview gpt-3.5-turbo-0125\n",
    "                    temperature=0,\n",
    "                    openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "afirmaciones = [\n",
      "    {\"Afirmación\": \"El empleo en España disminuyó en 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"La tasa de desempleo en España se situó en el 11,7% a finales de 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo público disminuyó en el último trimestre de 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El número de parados disminuyó en 24.600 personas en el último trimestre de 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo privado aumentó en 77.600 personas en el último trimestre de 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"Más de la mitad del empleo creado en 2023 fue para las mujeres.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El recorte de jornada laboral aumentará la creación de empleo en 2024.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"La tasa de temporalidad aumentó en 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo público aumentó en 58.600 personas en el último trimestre de 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El número total de ocupados a finales de 2023 fue inferior a 21 millones.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo creado en 2023 fue principalmente a tiempo parcial.\", \"Clasificación\": \"A medias\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El desempleo disminuyó en más de 190.000 personas durante 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El sector público fue el único que creó empleo en el último trimestre de 2023.\", \"Clasificación\": \"A medias\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"La población activa disminuyó durante el pasado año.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El ritmo de crecimiento del empleo en 2023 fue menor que en 2022.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"Todos los empleos creados en 2023 fueron en el sector privado.\", \"Clasificación\": \"A medias\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"La tasa de desempleo a finales de 2023 fue del 10%.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El número de parados a finales de 2023 fue inferior a 3 millones.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo aumentó en todos los trimestres de 2023.\", \"Clasificación\": \"A medias\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"La tasa de temporalidad se redujo en 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El Ministerio de Economía afirmó que el desempleo aumentó en 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"Más del 90% del empleo creado en 2023 fue a tiempo completo.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo en el sector público disminuyó en 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"La población activa aumentó en casi 600.000 personas durante 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo privado aumentó en más de 700.000 personas en 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El número de ocupados a finales de 2023 fue de aproximadamente 20 millones.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El desempleo se redujo en más del doble que el año anterior.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El recorte de jornada laboral planeado para 2024 beneficiará la creación de empleo.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El número de parados a finales de 2023 fue de 2.830.600.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo creado en 2023 fue principalmente en el sector público.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo disminuyó en el último trimestre de 2023 debido a la desaceleración económica.\", \"Clasificación\": \"A medias\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"La tasa de desempleo mejoró en comparación con 2022.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo privado fue el principal motor de creación de empleo en 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"La mayoría de los nuevos empleos en 2023 fueron a tiempo parcial.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El número de ocupados a finales de 2023 superó los 21,2 millones.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo aumentó en el sector público y privado en igual medida en 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El desempleo aumentó en el último trimestre de 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El número de parados disminuyó en más de 190.000 personas en 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"El empleo creado en 2023 fue exclusivamente a tiempo completo.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"},\n",
      "    {\"Afirmación\": \"La tasa de desempleo se mantuvo estable durante 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"abc\"}\n",
      "]\n",
      "\n",
      "df_afirmaciones = pd.DataFrame(afirmaciones)\n",
      "print(df_afirmaciones)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# ABC\n",
    "\n",
    "respuesta_eval = llm_eval.invoke('''\n",
    "Dato el siguiente texto, escribe 40 afirmaciones. Estas pueden ser de los siguientes tipos, tienes una explicación al respecto:\n",
    "- \"Refuta\": Crea una afirmación completamente falsa con respecto al texto.\n",
    "- \"Apoya\": Crea una afirmación completamente verdadera con respecto al texto.\n",
    "- \"A medias\": La información tiene algunas partes verdaderas y otras falsas acorde al contexto, con información contradictoria, o modificando algún detalle.\n",
    "- \"No hay información\": No existe información sobre la temática central de la información en el texto. Si no existe nada de información al respecto, elige esta opción.\n",
    "                                 \n",
    "Devuelve 10 afirmaciones de cada clasificación basándote en el texto proporcionado (debe haber el mismo número de Refuta, Apoya, A medias, No hay información).\n",
    "                                 \n",
    "Devuelvelo en formato tabla de Pandas con código en Python, con una columna sobre la afirmación, otra con la clasificación y otra con la fuente (en este caso, abc):\n",
    "afirmaciones = [\n",
    "    {\"Afirmación\": \"Afirmación generada\", \"Clasificación\": \"Clasificación generada\", \"Fuente\": \"abc\"},\n",
    "    ...,\n",
    "    {\"Afirmación\": \"Afirmación generada\", \"Clasificación\": \"Clasificación generada\", \"Fuente\": \"abc\"},                         \n",
    "]\n",
    "                                 \n",
    "El texto es el siguiente: '''\n",
    "+ documents[0].page_content)\n",
    "\n",
    "print(respuesta_eval.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "afirmaciones = [\n",
      "    {\"Afirmación\": \"El empleo en España disminuyó en 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El paro en España aumentó en 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"En 2023, el número de trabajadores en España fue menor que en 2022.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La tasa de paro en 2023 fue superior al 15%.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El sector público fue el principal generador de empleo en 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La mayoría de los empleos creados en 2023 fueron a tiempo parcial.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El paro aumentó en el último trimestre de 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"En 2023, España cerró el año con más de 3 millones de parados.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La tasa de paro en 2023 fue la más alta desde 2007.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El número de afiliados a la Seguridad Social disminuyó en 2023.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El empleo creció en 783.000 ocupados en 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El paro bajó al 11,7% en 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El número de trabajadores aumentó más en 2023 que en 2022.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El sector privado incorporó a 715.900 nuevos ocupados en 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La mayor parte de la ocupación creada en 2023 fue a tiempo completo.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El paro descendió en 193.400 personas en 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"España cerró 2023 con menos de 3 millones de parados.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La tasa de paro en 2023 fue la más baja desde 2007.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La población activa aumentó en casi 600.000 personas en 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El número de afiliados a la Seguridad Social creció en 540.000 personas en 2023.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El paro repuntó en el primer trimestre de 2023.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La creación de empleo en 2023 fue impulsada únicamente por el sector turístico.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"Todos los empleos creados en 2023 fueron permanentes.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El paro bajó en todos los trimestres de 2023.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La tasa de paro cerró el año 2023 exactamente en el 11,76%.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El empleo a tiempo parcial no experimentó ningún crecimiento en 2023.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El incremento de la ocupación en 2023 fue el doble que en 2022.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La tasa de paro al finalizar 2023 fue inferior al 10%.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El número de parados disminuyó en más de 200.000 personas en 2023.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La creación de empleo en 2023 no superó la cifra de 2019.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El informe sobre el empleo en 2023 fue publicado por la ONU.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El crecimiento del empleo en 2023 se debió principalmente a la tecnología blockchain.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La mayoría de los nuevos empleos en 2023 fueron en el sector de la inteligencia artificial.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El aumento del empleo en 2023 se concentró en las áreas rurales de España.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El incremento del empleo en 2023 fue impulsado por la industria del cine.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El crecimiento del empleo en 2023 se atribuye a la expansión de la economía verde.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"La reducción del paro en 2023 fue gracias a la implementación de políticas de teletrabajo.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El informe del INE sobre el empleo en 2023 incluyó un análisis detallado sobre el impacto del cambio climático en el mercado laboral.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El crecimiento del empleo en 2023 se vio favorecido por la legalización del cannabis.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elmundo\"},\n",
      "    {\"Afirmación\": \"El aumento de la población activa en 2023 se debió principalmente a la inmigración.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elmundo\"},\n",
      "]\n",
      "\n",
      "df_afirmaciones = pd.DataFrame(afirmaciones)\n",
      "print(df_afirmaciones)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# ElMundo\n",
    "\n",
    "respuesta_eval = llm_eval.invoke('''\n",
    "Dato el siguiente texto, escribe 40 afirmaciones. Estas pueden ser de los siguientes tipos, tienes una explicación al respecto:\n",
    "- \"Refuta\": Crea una afirmación completamente falsa con respecto al texto.\n",
    "- \"Apoya\": Crea una afirmación completamente verdadera con respecto al texto.\n",
    "- \"A medias\": La información tiene algunas partes verdaderas y otras falsas acorde al contexto, con información contradictoria, o modificando algún detalle.\n",
    "- \"No hay información\": No existe información sobre la temática central de la información en el texto. Si no existe nada de información al respecto, elige esta opción.\n",
    "                                 \n",
    "Devuelve 10 afirmaciones de cada clasificación basándote en el texto proporcionado (debe haber el mismo número de Refuta, Apoya, A medias, No hay información).\n",
    "                                 \n",
    "Devuelvelo en formato tabla de Pandas con código en Python, con una columna sobre la afirmación, otra con la clasificación y otra con la fuente (en este caso, elmundo):\n",
    "afirmaciones = [\n",
    "    {\"Afirmación\": \"Afirmación generada\", \"Clasificación\": \"Clasificación generada\", \"Fuente\": \"elmundo\"},\n",
    "    ...,\n",
    "    {\"Afirmación\": \"Afirmación generada\", \"Clasificación\": \"Clasificación generada\", \"Fuente\": \"elmundo\"},                         \n",
    "]\n",
    "                                 \n",
    "El texto es el siguiente: '''\n",
    "+ documents[1].page_content)\n",
    "\n",
    "print(respuesta_eval.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "afirmaciones = [\n",
      "    {\"Afirmación\": \"El paro aumentó en el último año.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"La tasa de desempleo es del 11,7%.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo a tiempo parcial disminuyó en el último año.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de hogares con todos sus miembros trabajando disminuyó.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo en el sector privado creció en 715.900 puestos.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"La tasa de temporalidad aumentó y superó la media europea.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de ocupados asciende a 2.246.900.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo a tiempo completo aumentó en más de 600.000 personas.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de hogares con al menos un miembro en paro aumentó.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"La población activa creció en casi 600.000 personas.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo en la Agricultura aumentó.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de afiliados a la Seguridad Social superó los 21 millones.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El paro en la Construcción aumentó.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo en los Servicios fue el único sector que aumentó su paro.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de hogares sin ningún activo disminuyó en el último trimestre.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo creció en igual medida entre hombres y mujeres.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"La tasa de desempleo se mantuvo estable en comparación con el año anterior.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo a tiempo parcial avanzó en 87.600 personas.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de hogares con al menos un activo no varió respecto a 2022.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo creció más en mujeres que en hombres.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"La tasa de variación anual de la población activa fue del 2,51%.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de parados aumentó en el último año.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo a tiempo completo disminuyó en el último año.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de hogares con todos sus miembros en paro se redujo en 115.110.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de ocupados es incorrecto según el texto.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo en el sector público fue el que más creció.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"La vicepresidenta y ministra de Trabajo y Economía Social es Yolanda Díaz.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El Gobierno planea reducir el número de empleados públicos.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo a tiempo parcial superó al empleo a tiempo completo en crecimiento.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de hogares con al menos un activo creció en 279.700 respecto a 2022.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"La tasa de desempleo es la más baja desde 2005.\", \"Clasificación\": \"A medias\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo en la Industria disminuyó.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de relaciones laborales indefinidas disminuyó.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo a tiempo completo creció menos que el empleo a tiempo parcial.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de hogares con todos sus miembros trabajando no alcanzó los 11 millones.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo en el sector de la Construcción creció.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"La tasa de temporalidad se colocó en el 13,2%.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El paro en los Servicios disminuyó.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El número de hogares sin ningún activo aumentó en el último año.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"elplural\"},\n",
      "    {\"Afirmación\": \"El empleo en el sector público disminuyó.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"elplural\"}\n",
      "]\n",
      "\n",
      "df_afirmaciones = pd.DataFrame(afirmaciones)\n",
      "print(df_afirmaciones)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# ElPlural\n",
    "\n",
    "respuesta_eval = llm_eval.invoke('''\n",
    "Dato el siguiente texto, escribe 40 afirmaciones. Estas pueden ser de los siguientes tipos, tienes una explicación al respecto:\n",
    "- \"Refuta\": Crea una afirmación completamente falsa con respecto al texto.\n",
    "- \"Apoya\": Crea una afirmación completamente verdadera con respecto al texto.\n",
    "- \"A medias\": La información tiene algunas partes verdaderas y otras falsas acorde al contexto, con información contradictoria, o modificando algún detalle.\n",
    "- \"No hay información\": No existe información sobre la temática central de la información en el texto. Si no existe nada de información al respecto, elige esta opción.\n",
    "                                 \n",
    "Devuelve 10 afirmaciones de cada clasificación basándote en el texto proporcionado (debe haber el mismo número de Refuta, Apoya, A medias, No hay información).\n",
    "                                 \n",
    "Devuelvelo en formato tabla de Pandas con código en Python, con una columna sobre la afirmación, otra con la clasificación y otra con la fuente (en este caso, elplural):\n",
    "afirmaciones = [\n",
    "    {\"Afirmación\": \"Afirmación generada\", \"Clasificación\": \"Clasificación generada\", \"Fuente\": \"elplural\"},\n",
    "    ...,\n",
    "    {\"Afirmación\": \"Afirmación generada\", \"Clasificación\": \"Clasificación generada\", \"Fuente\": \"elplural\"},                         \n",
    "]\n",
    "                                 \n",
    "El texto es el siguiente: '''\n",
    "+ documents[2].page_content)\n",
    "\n",
    "print(respuesta_eval.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "afirmaciones = [\n",
      "    {\"Afirmación\": \"Yolanda Díaz vive en un piso de 443 metros cuadrados.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz considera vivir en Madrid como una bendición.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"El piso de Yolanda Díaz está fuera del Ministerio de Trabajo y Economía Social.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz es la vicepresidenta primera del Gobierno.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"El piso de Yolanda Díaz es propiedad del Estado.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz es originaria de Madrid.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz disfruta de hacer sentadillas con su equipo.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"La hija de Yolanda Díaz esperaba encontrar gallinas en el piso de Madrid.\", \"Clasificación\": \"A medias\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz fue la última en llegar a la oficina según el presentador Marc Giró.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz afirmó que vivir en un ministerio es muy duro.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz prefiere vivir cerca del mar.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"El piso de Yolanda Díaz es el más pequeño entre los ocupados por los ministros del Ejecutivo.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz jugó a un juego de adivinanzas con Marc Giró durante la entrevista.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz confundió a Juana de Arco con Juana la Loca.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz expresó su amor por el mar durante la entrevista.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"La entrevista con Yolanda Díaz se realizó en un estudio de radio.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz tiene una hija que se sorprendió por la ausencia de gallinas en Galicia.\", \"Clasificación\": \"A medias\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz es conocida por su puntualidad extrema, siempre la primera en llegar y la última en irse.\", \"Clasificación\": \"A medias\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"La entrevista con Yolanda Díaz se emitió en el programa Late Xou de TVE.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz y Marc Giró discutieron sobre política internacional durante la entrevista.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz mencionó que le gusta 'besar y tocar' a la gente.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Marc Giró es el vicepresidente segundo del Gobierno.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz firmó su despido al final de la entrevista.\", \"Clasificación\": \"A medias\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz y Marc Giró realizaron ejercicios de sentadillas en directo.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"La casa de los padres de Yolanda Díaz en Galicia tenía cerdos, conejos y gallinas.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz criticó abiertamente a Isabel Díaz Ayuso durante la entrevista.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"El piso de Yolanda Díaz fue revelado por una pregunta de Vozpópuli.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz afirmó que vivir en Madrid le permite estar más cerca del mar.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz es la líder de Sumar.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"La entrevista se centró exclusivamente en la vida personal de Yolanda Díaz.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz mencionó que el horizonte y el mar enriquecen a las personas.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz vive en la zona de Nuevos Ministerios de Madrid.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz afirmó que odiar es preferible a mostrar afecto.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"El piso de Yolanda Díaz es el más grande ocupado por ministros del Ejecutivo de Pedro Sánchez.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz y Marc Giró hablaron sobre la posibilidad de que Madrid tenga mar en el futuro.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz realizó la entrevista desde su piso en Madrid.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz expresó su deseo de añadir un 'no conforme' al firmar un despido.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"La entrevista con Yolanda Díaz se realizó en un ambiente formal y serio.\", \"Clasificación\": \"No hay información\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz mencionó que le gusta trabajar obsesivamente.\", \"Clasificación\": \"Apoya\", \"Fuente\": \"okdiario\"},\n",
      "    {\"Afirmación\": \"Yolanda Díaz afirmó que vivir en un ministerio es fácil.\", \"Clasificación\": \"Refuta\", \"Fuente\": \"okdiario\"},\n",
      "]\n",
      "\n",
      "df = pd.DataFrame(afirmaciones)\n",
      "print(df)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# OKdiario\n",
    "\n",
    "respuesta_eval = llm_eval.invoke('''\n",
    "Dato el siguiente texto, escribe 40 afirmaciones. Estas pueden ser de los siguientes tipos, tienes una explicación al respecto:\n",
    "- \"Refuta\": Crea una afirmación completamente falsa con respecto al texto.\n",
    "- \"Apoya\": Crea una afirmación completamente verdadera con respecto al texto.\n",
    "- \"A medias\": La información tiene algunas partes verdaderas y otras falsas acorde al contexto, con información contradictoria, o modificando algún detalle.\n",
    "- \"No hay información\": No existe información sobre la temática central de la información en el texto. Si no existe nada de información al respecto, elige esta opción.\n",
    "                                 \n",
    "Devuelve 10 afirmaciones de cada clasificación basándote en el texto proporcionado (debe haber el mismo número de Refuta, Apoya, A medias, No hay información).\n",
    "                                 \n",
    "Devuelvelo en formato tabla de Pandas con código en Python, con una columna sobre la afirmación, otra con la clasificación y otra con la fuente (en este caso, okdiario):\n",
    "afirmaciones = [\n",
    "    {\"Afirmación\": \"Afirmación generada\", \"Clasificación\": \"Clasificación generada\", \"Fuente\": \"okdiario\"},\n",
    "    ...,\n",
    "    {\"Afirmación\": \"Afirmación generada\", \"Clasificación\": \"Clasificación generada\", \"Fuente\": \"okdiario\"},                         \n",
    "]\n",
    "                                 \n",
    "El texto es el siguiente: '''\n",
    "+ documents[3].page_content)\n",
    "\n",
    "print(respuesta_eval.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating responses with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Afirmación</th>\n",
       "      <th>Clasificación</th>\n",
       "      <th>Fuente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El empleo en España disminuyó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El paro en España aumentó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En 2023, el número de trabajadores en España f...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La tasa de paro en 2023 fue superior al 15%.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El sector público fue el principal generador d...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Afirmación Clasificación   Fuente\n",
       "0             El empleo en España disminuyó en 2023.        Refuta  elmundo\n",
       "1                 El paro en España aumentó en 2023.        Refuta  elmundo\n",
       "2  En 2023, el número de trabajadores en España f...        Refuta  elmundo\n",
       "3       La tasa de paro en 2023 fue superior al 15%.        Refuta  elmundo\n",
       "4  El sector público fue el principal generador d...        Refuta  elmundo"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.eval import eval_df\n",
    "\n",
    "eval_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 455, which is longer than the specified 200\n",
      "Created a chunk of size 212, which is longer than the specified 200\n",
      "Created a chunk of size 260, which is longer than the specified 200\n",
      "Created a chunk of size 240, which is longer than the specified 200\n",
      "Created a chunk of size 221, which is longer than the specified 200\n",
      "Created a chunk of size 243, which is longer than the specified 200\n",
      "Created a chunk of size 260, which is longer than the specified 200\n",
      "Created a chunk of size 215, which is longer than the specified 200\n",
      "Created a chunk of size 242, which is longer than the specified 200\n",
      "Created a chunk of size 240, which is longer than the specified 200\n",
      "Created a chunk of size 221, which is longer than the specified 200\n",
      "Created a chunk of size 243, which is longer than the specified 200\n",
      "Created a chunk of size 218, which is longer than the specified 200\n",
      "Created a chunk of size 407, which is longer than the specified 200\n",
      "Created a chunk of size 203, which is longer than the specified 200\n",
      "Created a chunk of size 243, which is longer than the specified 200\n",
      "Created a chunk of size 201, which is longer than the specified 200\n",
      "Created a chunk of size 299, which is longer than the specified 200\n",
      "Created a chunk of size 249, which is longer than the specified 200\n",
      "Created a chunk of size 240, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=30, separator=\".\")\n",
    "docs = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "vectorstore = FAISS.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0125\n",
      "1\n",
      "gpt-3.5-turbo-0125\n",
      "2\n",
      "gpt-3.5-turbo-0125\n",
      "3\n",
      "gpt-3.5-turbo-0125\n",
      "4\n",
      "gpt-3.5-turbo-0125\n",
      "5\n",
      "gpt-3.5-turbo-0125\n",
      "6\n",
      "gpt-3.5-turbo-0125\n",
      "7\n",
      "gpt-3.5-turbo-0125\n",
      "8\n",
      "gpt-3.5-turbo-0125\n",
      "9\n",
      "gpt-3.5-turbo-0125\n",
      "10\n",
      "gpt-3.5-turbo-0125\n",
      "11\n",
      "gpt-3.5-turbo-0125\n",
      "12\n",
      "gpt-3.5-turbo-0125\n",
      "13\n",
      "gpt-3.5-turbo-0125\n",
      "14\n",
      "gpt-3.5-turbo-0125\n",
      "15\n",
      "gpt-3.5-turbo-0125\n",
      "16\n",
      "gpt-3.5-turbo-0125\n",
      "17\n",
      "gpt-3.5-turbo-0125\n",
      "18\n",
      "gpt-3.5-turbo-0125\n",
      "19\n",
      "gpt-3.5-turbo-0125\n",
      "20\n",
      "gpt-3.5-turbo-0125\n",
      "21\n",
      "gpt-3.5-turbo-0125\n",
      "22\n",
      "gpt-3.5-turbo-0125\n",
      "23\n",
      "gpt-3.5-turbo-0125\n",
      "24\n",
      "gpt-3.5-turbo-0125\n",
      "25\n",
      "gpt-3.5-turbo-0125\n",
      "26\n",
      "gpt-3.5-turbo-0125\n",
      "27\n",
      "gpt-3.5-turbo-0125\n",
      "28\n",
      "gpt-3.5-turbo-0125\n",
      "29\n",
      "gpt-3.5-turbo-0125\n",
      "30\n",
      "gpt-3.5-turbo-0125\n",
      "31\n",
      "gpt-3.5-turbo-0125\n",
      "32\n",
      "gpt-3.5-turbo-0125\n",
      "33\n",
      "gpt-3.5-turbo-0125\n",
      "34\n",
      "gpt-3.5-turbo-0125\n",
      "35\n",
      "gpt-3.5-turbo-0125\n",
      "36\n",
      "gpt-3.5-turbo-0125\n",
      "37\n",
      "gpt-3.5-turbo-0125\n",
      "38\n",
      "gpt-3.5-turbo-0125\n",
      "39\n",
      "gpt-3.5-turbo-0125\n",
      "40\n",
      "gpt-3.5-turbo-0125\n",
      "41\n",
      "gpt-3.5-turbo-0125\n",
      "42\n",
      "gpt-3.5-turbo-0125\n",
      "43\n",
      "gpt-3.5-turbo-0125\n",
      "44\n",
      "gpt-3.5-turbo-0125\n",
      "45\n",
      "gpt-3.5-turbo-0125\n",
      "46\n",
      "gpt-3.5-turbo-0125\n",
      "47\n",
      "gpt-3.5-turbo-0125\n",
      "48\n",
      "gpt-3.5-turbo-0125\n",
      "49\n",
      "gpt-3.5-turbo-0125\n",
      "50\n",
      "gpt-3.5-turbo-0125\n",
      "51\n",
      "gpt-3.5-turbo-0125\n",
      "52\n",
      "gpt-3.5-turbo-0125\n",
      "53\n",
      "gpt-3.5-turbo-0125\n",
      "54\n",
      "gpt-3.5-turbo-0125\n",
      "55\n",
      "gpt-3.5-turbo-0125\n",
      "56\n",
      "gpt-3.5-turbo-0125\n",
      "57\n",
      "gpt-3.5-turbo-0125\n",
      "58\n",
      "gpt-3.5-turbo-0125\n",
      "59\n",
      "gpt-3.5-turbo-0125\n",
      "60\n",
      "gpt-3.5-turbo-0125\n",
      "61\n",
      "gpt-3.5-turbo-0125\n",
      "62\n",
      "gpt-3.5-turbo-0125\n",
      "63\n",
      "gpt-3.5-turbo-0125\n",
      "64\n",
      "gpt-3.5-turbo-0125\n",
      "65\n",
      "gpt-3.5-turbo-0125\n",
      "66\n",
      "gpt-3.5-turbo-0125\n",
      "67\n",
      "gpt-3.5-turbo-0125\n",
      "68\n",
      "gpt-3.5-turbo-0125\n",
      "69\n",
      "gpt-3.5-turbo-0125\n",
      "70\n",
      "gpt-3.5-turbo-0125\n",
      "71\n",
      "gpt-3.5-turbo-0125\n",
      "72\n",
      "gpt-3.5-turbo-0125\n",
      "73\n",
      "gpt-3.5-turbo-0125\n",
      "74\n",
      "gpt-3.5-turbo-0125\n",
      "75\n",
      "gpt-3.5-turbo-0125\n",
      "76\n",
      "gpt-3.5-turbo-0125\n",
      "77\n",
      "gpt-3.5-turbo-0125\n",
      "78\n",
      "gpt-3.5-turbo-0125\n",
      "79\n",
      "gpt-3.5-turbo-0125\n",
      "80\n",
      "gpt-3.5-turbo-0125\n",
      "81\n",
      "gpt-3.5-turbo-0125\n",
      "82\n",
      "gpt-3.5-turbo-0125\n",
      "83\n",
      "gpt-3.5-turbo-0125\n",
      "84\n",
      "gpt-3.5-turbo-0125\n",
      "85\n",
      "gpt-3.5-turbo-0125\n",
      "86\n",
      "gpt-3.5-turbo-0125\n",
      "87\n",
      "gpt-3.5-turbo-0125\n",
      "88\n",
      "gpt-3.5-turbo-0125\n",
      "89\n",
      "gpt-3.5-turbo-0125\n",
      "90\n",
      "gpt-3.5-turbo-0125\n",
      "91\n",
      "gpt-3.5-turbo-0125\n",
      "92\n",
      "gpt-3.5-turbo-0125\n",
      "93\n",
      "gpt-3.5-turbo-0125\n",
      "94\n",
      "gpt-3.5-turbo-0125\n",
      "95\n",
      "gpt-3.5-turbo-0125\n",
      "96\n",
      "gpt-3.5-turbo-0125\n",
      "97\n",
      "gpt-3.5-turbo-0125\n",
      "98\n",
      "gpt-3.5-turbo-0125\n",
      "99\n",
      "gpt-3.5-turbo-0125\n",
      "100\n",
      "gpt-3.5-turbo-0125\n",
      "101\n",
      "gpt-3.5-turbo-0125\n",
      "102\n",
      "gpt-3.5-turbo-0125\n",
      "103\n",
      "gpt-3.5-turbo-0125\n",
      "104\n",
      "gpt-3.5-turbo-0125\n",
      "105\n",
      "gpt-3.5-turbo-0125\n",
      "106\n",
      "gpt-3.5-turbo-0125\n",
      "107\n",
      "gpt-3.5-turbo-0125\n",
      "108\n",
      "gpt-3.5-turbo-0125\n",
      "109\n",
      "gpt-3.5-turbo-0125\n",
      "110\n",
      "gpt-3.5-turbo-0125\n",
      "111\n",
      "gpt-3.5-turbo-0125\n",
      "112\n",
      "gpt-3.5-turbo-0125\n",
      "113\n",
      "gpt-3.5-turbo-0125\n",
      "114\n",
      "gpt-3.5-turbo-0125\n",
      "115\n",
      "gpt-3.5-turbo-0125\n",
      "116\n",
      "gpt-3.5-turbo-0125\n",
      "117\n",
      "gpt-3.5-turbo-0125\n",
      "118\n",
      "gpt-3.5-turbo-0125\n",
      "119\n",
      "gpt-3.5-turbo-0125\n",
      "120\n",
      "gpt-3.5-turbo-0125\n",
      "121\n",
      "gpt-3.5-turbo-0125\n",
      "122\n",
      "gpt-3.5-turbo-0125\n",
      "123\n",
      "gpt-3.5-turbo-0125\n",
      "124\n",
      "gpt-3.5-turbo-0125\n",
      "125\n",
      "gpt-3.5-turbo-0125\n",
      "126\n",
      "gpt-3.5-turbo-0125\n",
      "127\n",
      "gpt-3.5-turbo-0125\n",
      "128\n",
      "gpt-3.5-turbo-0125\n",
      "129\n",
      "gpt-3.5-turbo-0125\n",
      "130\n",
      "gpt-3.5-turbo-0125\n",
      "131\n",
      "gpt-3.5-turbo-0125\n",
      "132\n",
      "gpt-3.5-turbo-0125\n",
      "133\n",
      "gpt-3.5-turbo-0125\n",
      "134\n",
      "gpt-3.5-turbo-0125\n",
      "135\n",
      "gpt-3.5-turbo-0125\n",
      "136\n",
      "gpt-3.5-turbo-0125\n",
      "137\n",
      "gpt-3.5-turbo-0125\n",
      "138\n",
      "gpt-3.5-turbo-0125\n",
      "139\n",
      "gpt-3.5-turbo-0125\n",
      "140\n",
      "gpt-3.5-turbo-0125\n",
      "141\n",
      "gpt-3.5-turbo-0125\n",
      "142\n",
      "gpt-3.5-turbo-0125\n",
      "143\n",
      "gpt-3.5-turbo-0125\n",
      "144\n",
      "gpt-3.5-turbo-0125\n",
      "145\n",
      "gpt-3.5-turbo-0125\n",
      "146\n",
      "gpt-3.5-turbo-0125\n",
      "147\n",
      "gpt-3.5-turbo-0125\n",
      "148\n",
      "gpt-3.5-turbo-0125\n",
      "149\n",
      "gpt-3.5-turbo-0125\n",
      "150\n",
      "gpt-3.5-turbo-0125\n",
      "151\n",
      "gpt-3.5-turbo-0125\n",
      "152\n",
      "gpt-3.5-turbo-0125\n",
      "153\n",
      "gpt-3.5-turbo-0125\n",
      "154\n",
      "gpt-3.5-turbo-0125\n",
      "155\n",
      "gpt-3.5-turbo-0125\n",
      "156\n",
      "gpt-3.5-turbo-0125\n",
      "157\n",
      "gpt-3.5-turbo-0125\n",
      "158\n",
      "gpt-3.5-turbo-0125\n",
      "159\n",
      "gpt-3.5-turbo-0125\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "from utils.funciones import consulta\n",
    "\n",
    "generated_outputs = []\n",
    "\n",
    "for index, row in eval_df.iterrows():\n",
    "    claim = row['Afirmación']\n",
    "\n",
    "    generated_text = consulta(claim, vectorstore, model=\"gpt-3.5-turbo-0125\", news=['abc', 'elplural', 'elmundo', 'okdiario'])\n",
    "    generated_outputs.append(generated_text)\n",
    "    print(len(generated_outputs))\n",
    "\n",
    "eval_df['output_gpt-3'] = generated_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Afirmación</th>\n",
       "      <th>Clasificación</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>output_gpt-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El empleo en España disminuyó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>(**Veredicto**: Refuta \\\\n**Justificación** : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El paro en España aumentó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>(**Veredicto**: Refuta  \\n**Justificación**: L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En 2023, el número de trabajadores en España f...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>(**Veredicto**: Refuta  \\n**Justificación**: L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La tasa de paro en 2023 fue superior al 15%.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>(**Veredicto**: Refuta \\\\n**Justificación**: L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El sector público fue el principal generador d...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>(**Veredicto**: Refuta  \\n**Justificación**: L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Afirmación Clasificación   Fuente  \\\n",
       "0             El empleo en España disminuyó en 2023.        Refuta  elmundo   \n",
       "1                 El paro en España aumentó en 2023.        Refuta  elmundo   \n",
       "2  En 2023, el número de trabajadores en España f...        Refuta  elmundo   \n",
       "3       La tasa de paro en 2023 fue superior al 15%.        Refuta  elmundo   \n",
       "4  El sector público fue el principal generador d...        Refuta  elmundo   \n",
       "\n",
       "                                        output_gpt-3  \n",
       "0  (**Veredicto**: Refuta \\\\n**Justificación** : ...  \n",
       "1  (**Veredicto**: Refuta  \\n**Justificación**: L...  \n",
       "2  (**Veredicto**: Refuta  \\n**Justificación**: L...  \n",
       "3  (**Veredicto**: Refuta \\\\n**Justificación**: L...  \n",
       "4  (**Veredicto**: Refuta  \\n**Justificación**: L...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(eval_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv('eval_gpt3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Afirmación</th>\n",
       "      <th>Clasificación</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>output_gpt-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El empleo en España disminuyó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta \\\\\\n**Justificación** ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El paro en España aumentó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En 2023, el número de trabajadores en España f...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La tasa de paro en 2023 fue superior al 15%.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta \\\\\\n**Justificación**:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El sector público fue el principal generador d...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Afirmación Clasificación   Fuente  \\\n",
       "0             El empleo en España disminuyó en 2023.        Refuta  elmundo   \n",
       "1                 El paro en España aumentó en 2023.        Refuta  elmundo   \n",
       "2  En 2023, el número de trabajadores en España f...        Refuta  elmundo   \n",
       "3       La tasa de paro en 2023 fue superior al 15%.        Refuta  elmundo   \n",
       "4  El sector público fue el principal generador d...        Refuta  elmundo   \n",
       "\n",
       "                                        output_gpt-3  \n",
       "0  ('**Veredicto**: Refuta \\\\\\n**Justificación** ...  \n",
       "1  ('**Veredicto**: Refuta  \\n**Justificación**: ...  \n",
       "2  ('**Veredicto**: Refuta  \\n**Justificación**: ...  \n",
       "3  ('**Veredicto**: Refuta \\\\\\n**Justificación**:...  \n",
       "4  ('**Veredicto**: Refuta  \\n**Justificación**: ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv('eval_gpt3.csv', index_col=0)\n",
    "eval_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cohere\n",
      "2\n",
      "cohere\n",
      "3\n",
      "cohere\n",
      "4\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "cohere\n",
      "10\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "cohere\n",
      "16\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "cohere\n",
      "18\n",
      "cohere\n",
      "19\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "cohere\n",
      "23\n",
      "cohere\n",
      "24\n",
      "cohere\n",
      "25\n",
      "cohere\n",
      "26\n",
      "cohere\n",
      "27\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "cohere\n",
      "31\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "cohere\n",
      "33\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "cohere\n",
      "35\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "cohere\n",
      "37\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "cohere\n",
      "39\n",
      "cohere\n",
      "40\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "cohere\n",
      "42\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "cohere\n",
      "46\n",
      "cohere\n",
      "47\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "cohere\n",
      "49\n",
      "cohere\n",
      "50\n",
      "cohere\n",
      "51\n",
      "cohere\n",
      "52\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "cohere\n",
      "55\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "cohere\n",
      "57\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "cohere\n",
      "59\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "cohere\n",
      "61\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "cohere\n",
      "68\n",
      "cohere\n",
      "69\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "cohere\n",
      "71\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "cohere\n",
      "73\n",
      "cohere\n",
      "74\n",
      "cohere\n",
      "75\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "cohere\n",
      "77\n",
      "cohere\n",
      "78\n",
      "cohere\n",
      "79\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "cohere\n",
      "81\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "cohere\n",
      "84\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "cohere\n",
      "86\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "cohere\n",
      "89\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "cohere\n",
      "91\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "cohere\n",
      "97\n",
      "cohere\n",
      "98\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "cohere\n",
      "102\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "cohere\n",
      "104\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "cohere\n",
      "106\n",
      "cohere\n",
      "107\n",
      "cohere\n",
      "108\n",
      "cohere\n",
      "109\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "cohere\n",
      "112\n",
      "cohere\n",
      "113\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "cohere\n",
      "117\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "cohere\n",
      "120\n",
      "cohere\n",
      "121\n",
      "cohere\n",
      "122\n",
      "cohere\n",
      "123\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "cohere\n",
      "125\n",
      "cohere\n",
      "126\n",
      "cohere\n",
      "127\n",
      "cohere\n",
      "128\n",
      "cohere\n",
      "129\n",
      "cohere\n",
      "130\n",
      "cohere\n",
      "131\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n",
      "cohere\n",
      "133\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "cohere\n",
      "135\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "cohere\n",
      "137\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "cohere\n",
      "139\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "cohere\n",
      "143\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "cohere\n",
      "146\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "cohere\n",
      "149\n",
      "cohere\n",
      "150\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "cohere\n",
      "154\n",
      "cohere\n",
      "155\n",
      "cohere\n",
      "156\n",
      "cohere\n",
      "157\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "cohere\n",
      "159\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "cohere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    }
   ],
   "source": [
    "from utils.funciones import consulta\n",
    "import time\n",
    "\n",
    "generated_outputs_cohere = []\n",
    "count = 1\n",
    "\n",
    "for index, row in eval_df.iterrows():\n",
    "    print(count)\n",
    "\n",
    "    if count % 2 == 0:\n",
    "        time.sleep(60)\n",
    "\n",
    "    claim = row['Afirmación']\n",
    "\n",
    "    generated_text = consulta(claim, vectorstore, model=\"cohere\", news=['abc', 'elplural', 'elmundo', 'okdiario'])\n",
    "    generated_outputs_cohere.append(generated_text)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "\n",
    "eval_df['output_cohere'] = generated_outputs_cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Afirmación</th>\n",
       "      <th>Clasificación</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>output_gpt-3</th>\n",
       "      <th>output_cohere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El empleo en España disminuyó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta \\\\\\n**Justificación** ...</td>\n",
       "      <td>( Veredicto: Apoya\\nJustificación: The affirma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El paro en España aumentó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "      <td>( **Veredicto**: Apoya \\\\n**Justificación**: E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En 2023, el número de trabajadores en España f...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "      <td>( Verdict: Apoya\\nJustification: The statement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La tasa de paro en 2023 fue superior al 15%.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta \\\\\\n**Justificación**:...</td>\n",
       "      <td>(\\n**Veredicto**: Apoya \\n**Justificación**: L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El sector público fue el principal generador d...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "      <td>(Sure, I understand the task and will classify...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Afirmación Clasificación   Fuente  \\\n",
       "0             El empleo en España disminuyó en 2023.        Refuta  elmundo   \n",
       "1                 El paro en España aumentó en 2023.        Refuta  elmundo   \n",
       "2  En 2023, el número de trabajadores en España f...        Refuta  elmundo   \n",
       "3       La tasa de paro en 2023 fue superior al 15%.        Refuta  elmundo   \n",
       "4  El sector público fue el principal generador d...        Refuta  elmundo   \n",
       "\n",
       "                                        output_gpt-3  \\\n",
       "0  ('**Veredicto**: Refuta \\\\\\n**Justificación** ...   \n",
       "1  ('**Veredicto**: Refuta  \\n**Justificación**: ...   \n",
       "2  ('**Veredicto**: Refuta  \\n**Justificación**: ...   \n",
       "3  ('**Veredicto**: Refuta \\\\\\n**Justificación**:...   \n",
       "4  ('**Veredicto**: Refuta  \\n**Justificación**: ...   \n",
       "\n",
       "                                       output_cohere  \n",
       "0  ( Veredicto: Apoya\\nJustificación: The affirma...  \n",
       "1  ( **Veredicto**: Apoya \\\\n**Justificación**: E...  \n",
       "2  ( Verdict: Apoya\\nJustification: The statement...  \n",
       "3  (\\n**Veredicto**: Apoya \\n**Justificación**: L...  \n",
       "4  (Sure, I understand the task and will classify...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eval_df.head(5))\n",
    "eval_df.to_csv('eval_cohere.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Afirmación</th>\n",
       "      <th>Clasificación</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>output_gpt-3</th>\n",
       "      <th>output_cohere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El empleo en España disminuyó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta \\\\\\n**Justificación** ...</td>\n",
       "      <td>(' Veredicto: Apoya\\nJustificación: The affirm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El paro en España aumentó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "      <td>(' **Veredicto**: Apoya \\\\\\n**Justificación**:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En 2023, el número de trabajadores en España f...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "      <td>(\" Verdict: Apoya\\nJustification: The statemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La tasa de paro en 2023 fue superior al 15%.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta \\\\\\n**Justificación**:...</td>\n",
       "      <td>('\\n**Veredicto**: Apoya \\n**Justificación**: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El sector público fue el principal generador d...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "      <td>('Sure, I understand the task and will classif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Afirmación Clasificación   Fuente  \\\n",
       "0             El empleo en España disminuyó en 2023.        Refuta  elmundo   \n",
       "1                 El paro en España aumentó en 2023.        Refuta  elmundo   \n",
       "2  En 2023, el número de trabajadores en España f...        Refuta  elmundo   \n",
       "3       La tasa de paro en 2023 fue superior al 15%.        Refuta  elmundo   \n",
       "4  El sector público fue el principal generador d...        Refuta  elmundo   \n",
       "\n",
       "                                        output_gpt-3  \\\n",
       "0  ('**Veredicto**: Refuta \\\\\\n**Justificación** ...   \n",
       "1  ('**Veredicto**: Refuta  \\n**Justificación**: ...   \n",
       "2  ('**Veredicto**: Refuta  \\n**Justificación**: ...   \n",
       "3  ('**Veredicto**: Refuta \\\\\\n**Justificación**:...   \n",
       "4  ('**Veredicto**: Refuta  \\n**Justificación**: ...   \n",
       "\n",
       "                                       output_cohere  \n",
       "0  (' Veredicto: Apoya\\nJustificación: The affirm...  \n",
       "1  (' **Veredicto**: Apoya \\\\\\n**Justificación**:...  \n",
       "2  (\" Verdict: Apoya\\nJustification: The statemen...  \n",
       "3  ('\\n**Veredicto**: Apoya \\n**Justificación**: ...  \n",
       "4  ('Sure, I understand the task and will classif...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv('eval_cohere.csv', index_col=0)\n",
    "eval_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-0125-preview\n",
      "1\n",
      "gpt-4-0125-preview\n",
      "2\n",
      "gpt-4-0125-preview\n",
      "3\n",
      "gpt-4-0125-preview\n",
      "4\n",
      "gpt-4-0125-preview\n",
      "5\n",
      "gpt-4-0125-preview\n",
      "6\n",
      "gpt-4-0125-preview\n",
      "7\n",
      "gpt-4-0125-preview\n",
      "8\n",
      "gpt-4-0125-preview\n",
      "9\n",
      "gpt-4-0125-preview\n",
      "10\n",
      "gpt-4-0125-preview\n",
      "11\n",
      "gpt-4-0125-preview\n",
      "12\n",
      "gpt-4-0125-preview\n",
      "13\n",
      "gpt-4-0125-preview\n",
      "14\n",
      "gpt-4-0125-preview\n",
      "15\n",
      "gpt-4-0125-preview\n",
      "16\n",
      "gpt-4-0125-preview\n",
      "17\n",
      "gpt-4-0125-preview\n",
      "18\n",
      "gpt-4-0125-preview\n",
      "19\n",
      "gpt-4-0125-preview\n",
      "20\n",
      "gpt-4-0125-preview\n",
      "21\n",
      "gpt-4-0125-preview\n",
      "22\n",
      "gpt-4-0125-preview\n",
      "23\n",
      "gpt-4-0125-preview\n",
      "24\n",
      "gpt-4-0125-preview\n",
      "25\n",
      "gpt-4-0125-preview\n",
      "26\n",
      "gpt-4-0125-preview\n",
      "27\n",
      "gpt-4-0125-preview\n",
      "28\n",
      "gpt-4-0125-preview\n",
      "29\n",
      "gpt-4-0125-preview\n",
      "30\n",
      "gpt-4-0125-preview\n",
      "31\n",
      "gpt-4-0125-preview\n",
      "32\n",
      "gpt-4-0125-preview\n",
      "33\n",
      "gpt-4-0125-preview\n",
      "34\n",
      "gpt-4-0125-preview\n",
      "35\n",
      "gpt-4-0125-preview\n",
      "36\n",
      "gpt-4-0125-preview\n",
      "37\n",
      "gpt-4-0125-preview\n",
      "38\n",
      "gpt-4-0125-preview\n",
      "39\n",
      "gpt-4-0125-preview\n",
      "40\n",
      "gpt-4-0125-preview\n",
      "41\n",
      "gpt-4-0125-preview\n",
      "42\n",
      "gpt-4-0125-preview\n",
      "43\n",
      "gpt-4-0125-preview\n",
      "44\n",
      "gpt-4-0125-preview\n",
      "45\n",
      "gpt-4-0125-preview\n",
      "46\n",
      "gpt-4-0125-preview\n",
      "47\n",
      "gpt-4-0125-preview\n",
      "48\n",
      "gpt-4-0125-preview\n",
      "49\n",
      "gpt-4-0125-preview\n",
      "50\n",
      "gpt-4-0125-preview\n",
      "51\n",
      "gpt-4-0125-preview\n",
      "52\n",
      "gpt-4-0125-preview\n",
      "53\n",
      "gpt-4-0125-preview\n",
      "54\n",
      "gpt-4-0125-preview\n",
      "55\n",
      "gpt-4-0125-preview\n",
      "56\n",
      "gpt-4-0125-preview\n",
      "57\n",
      "gpt-4-0125-preview\n",
      "58\n",
      "gpt-4-0125-preview\n",
      "59\n",
      "gpt-4-0125-preview\n",
      "60\n",
      "gpt-4-0125-preview\n",
      "61\n",
      "gpt-4-0125-preview\n",
      "62\n",
      "gpt-4-0125-preview\n",
      "63\n",
      "gpt-4-0125-preview\n",
      "64\n",
      "gpt-4-0125-preview\n",
      "65\n",
      "gpt-4-0125-preview\n",
      "66\n",
      "gpt-4-0125-preview\n",
      "67\n",
      "gpt-4-0125-preview\n",
      "68\n",
      "gpt-4-0125-preview\n",
      "69\n",
      "gpt-4-0125-preview\n",
      "70\n",
      "gpt-4-0125-preview\n",
      "71\n",
      "gpt-4-0125-preview\n",
      "72\n",
      "gpt-4-0125-preview\n",
      "73\n",
      "gpt-4-0125-preview\n",
      "74\n",
      "gpt-4-0125-preview\n",
      "75\n",
      "gpt-4-0125-preview\n",
      "76\n",
      "gpt-4-0125-preview\n",
      "77\n",
      "gpt-4-0125-preview\n",
      "78\n",
      "gpt-4-0125-preview\n",
      "79\n",
      "gpt-4-0125-preview\n",
      "80\n",
      "gpt-4-0125-preview\n",
      "81\n",
      "gpt-4-0125-preview\n",
      "82\n",
      "gpt-4-0125-preview\n",
      "83\n",
      "gpt-4-0125-preview\n",
      "84\n",
      "gpt-4-0125-preview\n",
      "85\n",
      "gpt-4-0125-preview\n",
      "86\n",
      "gpt-4-0125-preview\n",
      "87\n",
      "gpt-4-0125-preview\n",
      "88\n",
      "gpt-4-0125-preview\n",
      "89\n",
      "gpt-4-0125-preview\n",
      "90\n",
      "gpt-4-0125-preview\n",
      "91\n",
      "gpt-4-0125-preview\n",
      "92\n",
      "gpt-4-0125-preview\n",
      "93\n",
      "gpt-4-0125-preview\n",
      "94\n",
      "gpt-4-0125-preview\n",
      "95\n",
      "gpt-4-0125-preview\n",
      "96\n",
      "gpt-4-0125-preview\n",
      "97\n",
      "gpt-4-0125-preview\n",
      "98\n",
      "gpt-4-0125-preview\n",
      "99\n",
      "gpt-4-0125-preview\n",
      "100\n",
      "gpt-4-0125-preview\n",
      "101\n",
      "gpt-4-0125-preview\n",
      "102\n",
      "gpt-4-0125-preview\n",
      "103\n",
      "gpt-4-0125-preview\n",
      "104\n",
      "gpt-4-0125-preview\n",
      "105\n",
      "gpt-4-0125-preview\n",
      "106\n",
      "gpt-4-0125-preview\n",
      "107\n",
      "gpt-4-0125-preview\n",
      "108\n",
      "gpt-4-0125-preview\n",
      "109\n",
      "gpt-4-0125-preview\n",
      "110\n",
      "gpt-4-0125-preview\n",
      "111\n",
      "gpt-4-0125-preview\n",
      "112\n",
      "gpt-4-0125-preview\n",
      "113\n",
      "gpt-4-0125-preview\n",
      "114\n",
      "gpt-4-0125-preview\n",
      "115\n",
      "gpt-4-0125-preview\n",
      "116\n",
      "gpt-4-0125-preview\n",
      "117\n",
      "gpt-4-0125-preview\n",
      "118\n",
      "gpt-4-0125-preview\n",
      "119\n",
      "gpt-4-0125-preview\n",
      "120\n",
      "gpt-4-0125-preview\n",
      "121\n",
      "gpt-4-0125-preview\n",
      "122\n",
      "gpt-4-0125-preview\n",
      "123\n",
      "gpt-4-0125-preview\n",
      "124\n",
      "gpt-4-0125-preview\n",
      "125\n",
      "gpt-4-0125-preview\n",
      "126\n",
      "gpt-4-0125-preview\n",
      "127\n",
      "gpt-4-0125-preview\n",
      "128\n",
      "gpt-4-0125-preview\n",
      "129\n",
      "gpt-4-0125-preview\n",
      "130\n",
      "gpt-4-0125-preview\n",
      "131\n",
      "gpt-4-0125-preview\n",
      "132\n",
      "gpt-4-0125-preview\n",
      "133\n",
      "gpt-4-0125-preview\n",
      "134\n",
      "gpt-4-0125-preview\n",
      "135\n",
      "gpt-4-0125-preview\n",
      "136\n",
      "gpt-4-0125-preview\n",
      "137\n",
      "gpt-4-0125-preview\n",
      "138\n",
      "gpt-4-0125-preview\n",
      "139\n",
      "gpt-4-0125-preview\n",
      "140\n",
      "gpt-4-0125-preview\n",
      "141\n",
      "gpt-4-0125-preview\n",
      "142\n",
      "gpt-4-0125-preview\n",
      "143\n",
      "gpt-4-0125-preview\n",
      "144\n",
      "gpt-4-0125-preview\n",
      "145\n",
      "gpt-4-0125-preview\n",
      "146\n",
      "gpt-4-0125-preview\n",
      "147\n",
      "gpt-4-0125-preview\n",
      "148\n",
      "gpt-4-0125-preview\n",
      "149\n",
      "gpt-4-0125-preview\n",
      "150\n",
      "gpt-4-0125-preview\n",
      "151\n",
      "gpt-4-0125-preview\n",
      "152\n",
      "gpt-4-0125-preview\n",
      "153\n",
      "gpt-4-0125-preview\n",
      "154\n",
      "gpt-4-0125-preview\n",
      "155\n",
      "gpt-4-0125-preview\n",
      "156\n",
      "gpt-4-0125-preview\n",
      "157\n",
      "gpt-4-0125-preview\n",
      "158\n",
      "gpt-4-0125-preview\n",
      "159\n",
      "gpt-4-0125-preview\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "from utils.funciones import consulta\n",
    "\n",
    "generated_outputs = []\n",
    "\n",
    "for index, row in eval_df.iterrows():\n",
    "    claim = row['Afirmación']\n",
    "\n",
    "    generated_text = consulta(claim, vectorstore, model=\"gpt-4-0125-preview\", news=['abc', 'elplural', 'elmundo', 'okdiario'])\n",
    "    generated_outputs.append(generated_text)\n",
    "    print(len(generated_outputs))\n",
    "\n",
    "eval_df['output_gpt-4'] = generated_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Afirmación</th>\n",
       "      <th>Clasificación</th>\n",
       "      <th>Fuente</th>\n",
       "      <th>output_gpt-3</th>\n",
       "      <th>output_cohere</th>\n",
       "      <th>output_gpt-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El empleo en España disminuyó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta \\\\\\n**Justificación** ...</td>\n",
       "      <td>(' Veredicto: Apoya\\nJustificación: The affirm...</td>\n",
       "      <td>(**Veredicto**: Refuta \\\\n**Justificación**: L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El paro en España aumentó en 2023.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "      <td>(' **Veredicto**: Apoya \\\\\\n**Justificación**:...</td>\n",
       "      <td>(**Veredicto**: Apoya \\\\n**Justificación**: La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En 2023, el número de trabajadores en España f...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "      <td>(\" Verdict: Apoya\\nJustification: The statemen...</td>\n",
       "      <td>(**Veredicto**: Refuta\\n\\n**Justificación**: L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La tasa de paro en 2023 fue superior al 15%.</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta \\\\\\n**Justificación**:...</td>\n",
       "      <td>('\\n**Veredicto**: Apoya \\n**Justificación**: ...</td>\n",
       "      <td>(**Veredicto**: Refuta \\\\n**Justificación**: L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El sector público fue el principal generador d...</td>\n",
       "      <td>Refuta</td>\n",
       "      <td>elmundo</td>\n",
       "      <td>('**Veredicto**: Refuta  \\n**Justificación**: ...</td>\n",
       "      <td>('Sure, I understand the task and will classif...</td>\n",
       "      <td>(**Veredicto**: Refuta \\\\n**Justificación**: L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Afirmación Clasificación   Fuente  \\\n",
       "0             El empleo en España disminuyó en 2023.        Refuta  elmundo   \n",
       "1                 El paro en España aumentó en 2023.        Refuta  elmundo   \n",
       "2  En 2023, el número de trabajadores en España f...        Refuta  elmundo   \n",
       "3       La tasa de paro en 2023 fue superior al 15%.        Refuta  elmundo   \n",
       "4  El sector público fue el principal generador d...        Refuta  elmundo   \n",
       "\n",
       "                                        output_gpt-3  \\\n",
       "0  ('**Veredicto**: Refuta \\\\\\n**Justificación** ...   \n",
       "1  ('**Veredicto**: Refuta  \\n**Justificación**: ...   \n",
       "2  ('**Veredicto**: Refuta  \\n**Justificación**: ...   \n",
       "3  ('**Veredicto**: Refuta \\\\\\n**Justificación**:...   \n",
       "4  ('**Veredicto**: Refuta  \\n**Justificación**: ...   \n",
       "\n",
       "                                       output_cohere  \\\n",
       "0  (' Veredicto: Apoya\\nJustificación: The affirm...   \n",
       "1  (' **Veredicto**: Apoya \\\\\\n**Justificación**:...   \n",
       "2  (\" Verdict: Apoya\\nJustification: The statemen...   \n",
       "3  ('\\n**Veredicto**: Apoya \\n**Justificación**: ...   \n",
       "4  ('Sure, I understand the task and will classif...   \n",
       "\n",
       "                                        output_gpt-4  \n",
       "0  (**Veredicto**: Refuta \\\\n**Justificación**: L...  \n",
       "1  (**Veredicto**: Apoya \\\\n**Justificación**: La...  \n",
       "2  (**Veredicto**: Refuta\\n\\n**Justificación**: L...  \n",
       "3  (**Veredicto**: Refuta \\\\n**Justificación**: L...  \n",
       "4  (**Veredicto**: Refuta \\\\n**Justificación**: L...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.to_csv('eval_gpt4.csv')\n",
    "eval_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
